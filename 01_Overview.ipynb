{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lecture 1: Getting Started\n",
    "## Graphs & Sessions\n",
    "\n",
    "    \n",
    "### 1. Tensor\n",
    "- def: n-dimensional matrix\n",
    "    - 0-d tensor: scalar (number)\n",
    "    - 1-d tensor: vector\n",
    "    - 2-d tensor: matrix\n",
    "- tensors are data -> data flow=tensor flow\n",
    "    \n",
    "### 2. Data flow graphs\n",
    "- TF separates definition of computations from their execution\n",
    "- phases\n",
    "    1. assemble a graph\n",
    "    2. use a session to execute operations in the graph\n",
    "- elements\n",
    "    1. nodes:  operators, variables, and constants\n",
    "    2. edges:  tensors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.add(3, 5) #can be visualized by tensorboard\n",
    "print( a )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get the value of a\n",
    "- Create a session, assign it to a variable (sess)\n",
    "- Within the session, evaluate the graph to fetch the value of a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() #get the value of a\n",
    "print(sess.run(a))\n",
    "sess.close() \n",
    "\n",
    "# with clause takes care\n",
    "# of sess.close()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 2\n",
    "y = 3\n",
    "op1 = tf.add(x, y)\n",
    "op2 = tf.multiply(x, y)\n",
    "useless = tf.multiply(x, op1)\n",
    "op3 = tf.pow(op2, op1)\n",
    "with tf.Session() as sess:\n",
    "    op3 = sess.run(op3) # session wonâ€™t compute values of useless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    op3, not_useless = sess.run([op3, useless])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible to break graphs into several chunks and run them parallelly across multiple CPUs, GPUs, or devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a graph.\n",
    "with tf.device('/gpu:2'):\n",
    " a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='a')\n",
    " b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='b')\n",
    " c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print sess.run(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. more than 1 graph?\n",
    "- not necessary\n",
    "- Multiple graphs require multiple sessions, each will try to use all available resources by default\n",
    "- Can't pass data between them without passing them through python/numpy, which doesn't work in distributed \n",
    "- better to have <u>disconnected subgraphs within one graph</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add operators to a graph, set it as default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    a = 3\n",
    "    b = 5\n",
    "    x = tf.add(a, b)\n",
    "sess = tf.Session(graph=g)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle the default graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do NOT mix default graph and user created graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prone to errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "# add ops to the default graph\n",
    "a = tf.constant(3)\n",
    "# add ops to the user created graph\n",
    "with g.as_default():\n",
    "b = tf.constant(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- improvement, but not good enough because no more than one graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g1 = tf.get_default_graph()\n",
    "g2 = tf.Graph()\n",
    "# add ops to the default graph\n",
    "with g1.as_default():\n",
    "a = tf.Constant(3)\n",
    "# add ops to the user created graph\n",
    "with g2.as_default():\n",
    "b = tf.Constant(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Why graphs?\n",
    "1. <u>Save computation</u> (only run subgraphs that lead to the values you want to fetch)\n",
    "2. Break computation into small, differential pieces to <u>facilitates auto-differentiation</u>\n",
    "3. <u>Facilitate distributed computation</u>, spread the work across multiple CPUs, GPUs, or devices\n",
    "4. Many common machine learning models are commonly taught and visualized as directed graphs already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
