{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 9: Input Pipeline\n",
    "### 0. Overview\n",
    "- Queues and Coordinators\n",
    "- Data Readers Revisited\n",
    "- TFRecord\n",
    "- Variable Initializer\n",
    "- Graph Collection\n",
    "- Style Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Queues and Coordinators\n",
    "#### 1.1 Queues: for computing tensors asynchronously in a graph\n",
    "advantages:\n",
    "- Multiple threads prepare training examples and push them in the queue\n",
    "- A training thread executes a training op that dequeues mini-batches from the queue\n",
    "\n",
    "challenges:\n",
    "- All threads must be able to stop together\n",
    "- Exceptions must be caught and reported\n",
    "- Queues must be properly closed when stopping.\n",
    "\n",
    "**TensorFlow queues can’t run without proper threading,\n",
    "but threading isn’t exactly pleasant in Python **  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 two classes to help with the threading: \n",
    "- `tf.Coordinator`: helps multiple threads stop together and report exceptions to a program that waits for them to stop\n",
    "- `tf.train.QueueRunner`: create a number of threads cooperating to enqueue tensors in the same queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 queue classes\n",
    "![queueclass](figures/09_01.png)\n",
    "\n",
    "- common practice: enqueue many examples in when reading data, but dequeue them one by one\n",
    "- to get multiple elements at once for your batch training: use `tf.train.batch` or `tf.train.shuffle_batch` if you want to your batch to be shuffled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Queue is always used with string_input_producer\n",
    "\n",
    "#### 1.5 example\n",
    "09_queue_example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_SAMPLES = 1000\n",
    "NUM_THREADS = 4\n",
    "\n",
    "# Generating some simple data\n",
    "# create 1000 random samples, each is a 1D array from the normal distribution (10, 1)\n",
    "data = 10 * np.random.randn(N_SAMPLES, 4) + 1\n",
    "\n",
    "# create 1000 random labels of 0 and 1\n",
    "target = np.random.randint(0, 2, size=N_SAMPLES)\n",
    "\n",
    "queue = tf.FIFOQueue(capacity=50, dtypes=[tf.float32, tf.int32], shapes=[[4], []])\n",
    "\n",
    "# create ops that do something with data_sample and label_sample\n",
    "enqueue_op = queue.enqueue_many([data, target])\n",
    "data_sample, label_sample = queue.dequeue()\n",
    "\n",
    "# create NUM_THREADS to do enqueue\n",
    "qr = tf.train.QueueRunner(queue, [enqueue_op] * NUM_THREADS)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Create a coordinator, launch the queue runner threads.\n",
    "    coord = tf.train.Coordinator()\n",
    "    enqueue_threads = qr.create_threads(sess, coord=coord, start=True)\n",
    "    for step in xrange(100): # do to 100 iterations\n",
    "        if coord.should_stop():\n",
    "            break\n",
    "    data_batch, label_batch = sess.run([data_sample, label_sample])\n",
    "    coord.request_stop()\n",
    "    coord.join(enqueue_threads)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "more examples in CS 110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2. Data Readers\n",
    "previously mentioned in [Lecture 5](05_Managing experiments and process data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 `tf.train.string_input_producer`: create a queue to hold the names of all the files to be read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "filename_queue = tf.train.string_input_producer([\"heart.csv\"])\n",
    "reader = tf.TextLineReader(skip_header_lines=1)\n",
    "    # it means you choose to skip the first line for every file in the queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of readers as ops that return a different value every time you call it -- similar to Python generators\n",
    "- key: a key to identify the file and record (useful for debugging if you have some weird records)\n",
    "- value: a scalar string value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key, value = reader.read(filename_queue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each example, the call to read() above might return:\n",
    "\n",
    "    key = data/heart.csv:2\n",
    "    value = 144,0.01,4.41,28.61,Absent,55,28.87,2.06,63,1\n",
    "    #  value “144,0.01,4.41,28.61,Absent,55,28.87,2.06,63,1” is the second line\n",
    "    # (excluding the header line) in the file heart.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.train.string_input_producer` creates a FIFOQueue under the hood  \n",
    "-> need `tf.Coordinator` and `tf.QueueRunner` to run the queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2  run the queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer(filenames)\n",
    "reader = tf.TextLineReader(skip_header_lines=1) # skip the first line in the file\n",
    "key, value = reader.read(filename_queue)\n",
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    print(sess.run(key)) # data/heart.csv:2\n",
    "    print(sess.run(value)) # 144,0.01,4.41,28.61,Absent,55,28.87,2.06,63,1\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 TensorFlow CSV decoder: convert string into vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content = tf.decode_csv(value, record_defaults=record_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- will parse value into the tensor record defaults which we have to create ourselves\n",
    "- the record defaults serve two purposes\n",
    "    - tells the decoder what **types** of data to expect in each column\n",
    "    - in case of missing data in file, will fill in that space with the **default value of the data type** that we specify\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# an example of record defaults\n",
    "record_defaults = [[1.0] for _ in range(N_FEATURES)] # define all features to be floats\n",
    "record_defaults[4] = [''] # make the fifth feature string\n",
    "record_defaults.append([1]) # make last column (label) integer\n",
    "content = tf.decode_csv(value, record_defaults=record_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4  data pre-processing\n",
    "single sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the 5th column (present/absent) to the binary value 0 and 1\n",
    "condition = tf.equal(content[4], tf.constant('Present'))\n",
    "content[4] = tf.select(condition, tf.constant(1.0), tf.constant(0.0))\n",
    "# pack all 9 features into a tensor\n",
    "features = tf.pack(content[:N_FEATURES])\n",
    "# assign the last column to label\n",
    "label = content[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch ‘em up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# minimum number elements in the queue after a dequeue, used to ensure\n",
    "# that the samples are sufficiently mixed\n",
    "# I think 10 times the BATCH_SIZE is sufficient\n",
    "min_after_dequeue = 10 * BATCH_SIZE\n",
    "# the maximum number of elements in the queue\n",
    "capacity = 20 * BATCH_SIZE\n",
    "# shuffle the data to generate BATCH_SIZE sample pairs\n",
    "data_batch, label_batch = tf.train.shuffle_batch([features, label], batch_size=BATCH_SIZE,\n",
    "                                                 capacity=capacity, min_after_dequeue=min_after_dequeue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full code see [Github Repo](https://github.com/chiphuyen/tf-stanford-tutorials/blob/master/examples/05_csv_reader.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TFRecord: TensorFlow's binary data format\n",
    "A TFRecord is a serialized `tf.train.Example` Protobuf object. \n",
    "\n",
    "#### 3.0 why binary data?\n",
    "- make better use of disk cache\n",
    "- faster to move around\n",
    "- can store data of different types (so you can put both images and labels in one place)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 read in the image and convert it to byte string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_binary(filename):\n",
    "    image = Image.open(filename)\n",
    "    image = np.asarray(image, np.uint8)\n",
    "    shape = np.array(image.shape, np.int32)\n",
    "    return shape.tobytes(), image.tobytes() # convert image to raw data bytes in the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 write the byte strings into a TFRecord file\n",
    "Use `tf.python_io.TFRecordWriter` and `tf.train.Features`  \n",
    "**Note:** Need the shape information so you can reconstruct the image from the binary format later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_tfrecord(label, shape, binary_image, tfrecord_file):\n",
    "    \"\"\" This example is to write a sample to TFRecord file. If you want to write\n",
    "    more samples, just use a loop.\n",
    "    \"\"\"\n",
    "    writer = tf.python_io.TFRecordWriter(tfrecord_file)\n",
    "    # write label, shape, and image content to the TFRecord file\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'label': tf.train.Feature(bytes_list=tf.train.BytesList(value=[label])),\n",
    "        'shape': tf.train.Feature(bytes_list=tf.train.BytesList(value=[shape])),\n",
    "        'image':tf.train.Feature(bytes_list=tf.train.BytesList(value=[binary_image]))\n",
    "    }))\n",
    "    writer.write(example.SerializeToString())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3  read a TFRecord file\n",
    "Use `TFRecordReader` and `tf.decode_raw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_from_tfrecord(filenames):\n",
    "    tfrecord_file_queue = tf.train.string_input_producer(filenames, name='queue')\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, tfrecord_serialized = reader.read(tfrecord_file_queue)\n",
    "    \n",
    "    # label and image are stored as bytes but could be stored as\n",
    "    # int64 or float64 values in a serialized tf.Example protobuf.\n",
    "    tfrecord_features = tf.parse_single_example(tfrecord_serialized,\n",
    "                                                features={\n",
    "                                                    'label': tf.FixedLenFeature([], tf.string),\n",
    "                                                    'shape': tf.FixedLenFeature([], tf.string),\n",
    "                                                    'image': tf.FixedLenFeature([], tf.string),\n",
    "                                                }, name='features')\n",
    "    # image was saved as uint8, so we have to decode as uint8.\n",
    "    image = tf.decode_raw(tfrecord_features['image'], tf.uint8)\n",
    "    shape = tf.decode_raw(tfrecord_features['shape'], tf.int32)\n",
    "    \n",
    "    # the image tensor is flattened out, so we have to reconstruct the shape\n",
    "    image = tf.reshape(image, shape)\n",
    "    label = tf.cast(tfrecord_features['label'], tf.string)\n",
    "    return label, shape, image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**  `label`, `shape`, and `image` returned are tensor objects. To get their values, you’ll have to eval them in `tf.Session()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Style Transfer\n",
    "[paper](https://arxiv.org/pdf/1701.04928v1.pdf)  \n",
    "\n",
    "#### 4.1 goal explained\n",
    "Find a new image:  \n",
    "- whose content is closest to the content image and\n",
    "- whose style is closest to the style image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 What is the content/style of an image?\n",
    "Feature visualization have shown that:\n",
    "- lower layers extract features related to content\n",
    "- higher layers extract features related to style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 all about the loss functions:\n",
    "- **Content loss**: $L_{content}(\\vec{p}, \\vec{x},l)=\\frac{1}{2} \\sum_{i,j}(F_{ij}^l-P_{ij}^l)^2$\n",
    "    - To measure the content loss between the content (**the feature map in the content layer**) of the generated image and the content of the content image\n",
    "    - Paper: `'conv4_4'`\n",
    "- **Style loss**: $L_{style}(\\vec{a}, \\vec{x})=\\sum_{l=0}^L w_lE_l,\\qquad E_l=\\frac{1}{4N_l^2 M_l^2}\\sum_{i,j}(G_{ij}^l-A_{ij}^l)^2$\n",
    "    - To measure the style loss between the style (**the feature maps in the style layers ->  the gram matrices of feature maps in the style layers**) of the generated image and the style of the style image\n",
    "    - Paper: `[‘conv1_1’, ‘conv2_1’, ‘conv3_1’, ‘conv4_1’ and ‘conv5_1’]`\n",
    "    - Give more weight to deeper layers: E.g. 1.0 for `‘conv1_1’`, 2.0 for `‘conv2_1’`, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 optimizer\n",
    "Optimizes the **initial image** (not the weights!) to minimize the combination of the two losses  \n",
    "$$L_{total}(\\vec{p}, \\vec{a}, \\vec{x})= \\alpha L_{content}(\\vec{p}, \\vec{x})+ \\beta L_{style}(\\vec{a}, \\vec{x})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Tricky implementation details\n",
    "- Train input instead of weights\n",
    "- Multiple tensors share the same variable to avoid assembling identical subgraphs\n",
    "    - content image\n",
    "    - style image\n",
    "    - initial image\n",
    "- Use pre-trained weights (from VGG-19)\n",
    "    - Weights and biases already loaded for you\n",
    "    - They are numpy, so need to be converted to tensors\n",
    "    - Must not be trainable!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
